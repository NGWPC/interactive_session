<tool id='Matthew.Shaxted_interactive_session' name='Matthew.Shaxted_interactive_session'>
  <command interpreter='bash'>main.sh</command>
  <inputs>
    <section name='service_sec' type='section' title='Service' expanded='true'>
        <conditional name="service_env_cond">
            <param name='service_name' type='select' label='Interactive service to run:' width='50%_none' optional='false' multiple='false'>
                <option value="jupyter-host">Jupyter Notebook</option>
                <option value="webshell">Webshell</option>
                <option value="turbovnc">Desktop</option>
                <option value="netcat-tester">netcat-tester</option>
                <option value="r-singularity" >r-singularity</option>
                <option value="jupyter-docker" >jupyter-docker</option>
                <option value="jupyter-singularity" >jupyter-singularity</option>
                <option value="novnc-docker" >novnc-docker</option>
            </param>
            <when value="turbovnc">
                <param name='slurm_module' label='Slurm module' type='text' value=''  help='Select the module name for any additional service to launch' width='50%_none'></param>
                <param name='service_bin' label='Service binary' type='text' value='' help='Select the binary for any additional service to launch' width='50%_none'></param>
                <param name="service_background" type="boolean" truevalue="Yes" falsevalue="No" checked="True" label="un service in background?" help='Select Yes to run the GUI service in the background' width="25%_none" optional='true' float="right"></param>
            </when>
            <when value="jupyter-host">
                <param name='conda_sh' label='Path to conda.sh' type='text' value='/contrib/anaconda/anaconda3/latest/etc/profile.d/conda.sh' help='Path to use in source /path/to/conda.sh' width='50%_none'></param>
                <param name='conda_env' label='Conda environment (recommened: base)' type='text' value='base' help='Environment to active. The base environment enables changing kernel to other environments!' width='50%_none'></param>
                <param name='password' label='Password for notebook access:' type='text' value='EnterPassword' help='' width='50%_none'></param>
            </when>
            <when value="r-singularity">
                <param name='path_to_sing' label='Path to singularity container' type='text' value='/home/\${USER}/rserver.sif' help='Path to the singularity container in the execution host' width='50%_none'></param>
                <param name='mount_dirs' label='Mount -B options. Use ___ instead of spaces. Use absolute paths!' type='text' value='-B___\${PWD}:\${PWD}' help='Can list several directories but need to use three _ characters to separate them' width='50%_none'></param>
            </when>
            <when value="jupyter-docker">
                <param name='docker_repo' label='Docker repository' type='text' value='jupyter/datascience-notebook:hub-2.3.1' help='Docker repository to start with docker run' width='50%_none'></param>
                <param name="use_gpus" type="boolean" truevalue="Yes" falsevalue="No" checked="False" label="Use GPUs?" help='Select Yes to run a CUDA application inside a container' width="25%_none" optional='true' float="right"></param>
            </when>
            <when value="jupyter-singularity">
                <param name='path_to_sing' label='Path to singularity container' type='text' value='/home/\${USER}/tensorflow_latest-gpu-jupyter-extra.sif' help='Path to the singularity container in the execution host' width='50%_none'></param>
                <param name='mount_dirs' label='Mount -B options. Use ___ instead of spaces. Use absolute paths!' type='text' value='-B___\${PWD}:\${PWD}' help='Can list several directories but need to use three _ characters to separate them' width='50%_none'></param>
                <param name="use_gpus" type="boolean" truevalue="Yes" falsevalue="No" checked="False" label="Use GPUs?" help='Select Yes to run a CUDA application inside a container' width="25%_none" optional='true' float="right"></param>
            </when>
            <when value="novnc-docker">
                <param name='docker_repo' type='select' label='noVNC Docker Container' help='Docker container to serve for the noVNC session' width='50%_none' multiple='false'>
                    <option value="accetto/ubuntu-vnc-xfce-opengl-g3" selected="true">Ubuntu 20.04 Xfce OpenGL</option>
                    <option value="accetto/ubuntu-vnc-xfce-python-g3">Ubuntu 20.04 Xfce Python</option>
                    <option value="accetto/ubuntu-vnc-xfce-nodejs-g3">Ubuntu 20.04 Xfce NodeJS</option>
                    <option value="accetto/ubuntu-vnc-xfce-freecad-g3">Ubuntu 20.04 Xfce FreeCAD</option>
                    <option value="accetto/ubuntu-vnc-xfce-postman-g3">Ubuntu 20.04 Xfce Postman</option>
                    <option value="accetto/ubuntu-vnc-xfce-blender-g3">Ubuntu 20.04 Xfce Blender</option>
                    <option value="accetto/ubuntu-vnc-xfce-gimp-g3">Ubuntu 20.04 Xfce Gimp</option>
                    <option value="accetto/ubuntu-vnc-xfce-inkscape-g3">Ubuntu 20.04 Xfce Inkscape</option>
                    <option value="accetto/ubuntu-vnc-xfce-drawio-g3">Ubuntu 20.04 Xfce DrawIO</option>
                    <option value="accetto/ubuntu-vnc-xfce-firefox-g3">Ubuntu 20.04 Xfce Firefox</option>
                    <option value="accetto/ubuntu-vnc-xfce-chromium-g3">Ubuntu 20.04 Xfce Chromium</option>
                </param>
                <param name="use_gpus" type="boolean" truevalue="Yes" falsevalue="No" checked="False" label="Use GPUs?" help='Select Yes to run a CUDA application inside a container' width="25%_none" optional='true' float="right"></param>
            </when>
        </conditional>
    </section>
    <section name='host' type='section' title='Service Host' expanded='false'>
      <param name='account' label='Slurm account:' type='text' help='Account to submit the interactive job to.' value='nesccmgmt' width='50%_none'>
      </param>
      <conditional name="partition_or_controller_cond">
            <param name="partition_or_controller" type="boolean" truevalue="Partition" falsevalue="Controller" checked="True" label="Partition or controller node?" help='Choose to run the service in the controller / login or partition / compute nodes' width="25%_none" optional='true' float="right"></param>
            <when value="Partition">
                <param name='partition' label='Slurm partition:' type='text' help='Partition to submit the interactive job to.' value='default' width='50%_none'>
                </param>
                <param name='numnodes' label='Number of nodes:' type='integer' min="1" max="10" help='Number of nodes to request for the interactive session.' value='1' width='50%_none'>
                </param>
                <param name="exclusive" type="boolean" truevalue="Yes" falsevalue="No" checked="True" label="Exclusive" help='The job allocation can not share nodes with other running jobs' width="25%_none" optional='true' float="right">
                </param>
            </when>
        </conditional>
    <param name='walltime' placeholder="test" type='text' help='e.g. 00:10:00 - Amount of time slurm will honor the interactive session.' value='00:20:00' width='50%_none'>
    </param>
    </section>
    <section name='advanced_options_other' type='section' title='Advanced Options' expanded='false'>
        <conditional name="isession_clone_latest_cond">
            <param name="isession_clone_latest" type="boolean" truevalue="Yes" falsevalue="No" checked="False" label="Clone interactive_session repository?" help='Clone repository or use the local copy of the repository' width="25%_none" optional='true' float="right"/>
            <when value="Yes">
                <param name='isession_repo_url' label='URL of repository' type='text' help='This is passed to command: git clone --recurse-submodules' value='https://github.com/parallelworks/interactive_session.git' width='50%_none'>
                </param>
                <param name='isession_repo_branch' label='Branch name' type='text' help='Name of the Github branch to check out: git checkout branch-name' value='main' width='50%_none'>
                </param>
            </when>
        </conditional>
        <param name="stream" type="boolean" truevalue="Yes" falsevalue="No" checked="True" label="Stream slurm output?" help='Select Yes to stream the slurm output from the execution host to the job directory in PW' width="25%_none" optional='true' float="right">
        </param>
        <param name='controller' label='Controller host' type='text' value='pw.conf' help='Use hostname@ip or a proxy like PoolName.clusters.pw. Use pw.conf to get PoolName from pw.conf' width='50%_none'>
        </param>
        <param name='chdir' label='Working directory of the batch script' type='text' value='/home/\$(whoami)/__job_number__' help='Working directory of the batch script to directory before it is executed' width='50%_none'>
        </param>
        <param name='servicePort' label='Interactive remote service port' type='text' help='Port of the listening service on the remote compute node' value='6080' width='50%_none'>
        </param>
    </section>
  </inputs>
  <outputs>
  </outputs>
</tool>
