{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01478796-80e0-49bb-b87c-c5b2e8dff08e",
   "metadata": {},
   "source": [
    "# Interactive Dask on SLURMCluster: JupyterLab Tutorial for Distributed Data Processing and AWS Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96bacab-7327-452c-ae5f-2a9436688890",
   "metadata": {},
   "source": [
    "This notebook provides a tutorial on running Dask in a SLURMCluster using a JupyterLab interactive session. The steps include:\n",
    "\n",
    "1. SLURM Cluster Configuration: Define a SLURM cluster configuration using the SLURMCluster object, specifying parameters like the compute queue, number of CPU cores per job, and memory allocation. The cluster is then scaled to a desired number of workers using the adapt method.\n",
    "\n",
    "2. Connect to Dask Cluster: A Dask client is connected to the SLURMCluster, enabling interaction with the Dask computation.\n",
    "\n",
    "3. Display Dask Dashboard in Jupyter Lab: Utilize the Dask extension for JupyterLab to integrate the Dask Dashboard directly. Instructions are provided to establish the connection to the dashboard.\n",
    "\n",
    "4. Set AWS Credentials: Set temporary AWS credentials to access an AWS bucket resource defined in the Parallel Works platform, facilitating data transfer.\n",
    "\n",
    "5. Generate Random Data: Create a Dask DataFrame with randomly generated data, and adjust the number of rows as needed.\n",
    "\n",
    "6. Write and Read Data to/from AWS Bucket: Write the generated data to the specified AWS bucket and read it back into a Dask DataFrame.\n",
    "\n",
    "7. Process Data: Perform data processing on the Dask DataFrame, filtering rows and grouping by specific columns.\n",
    "\n",
    "7. Write Processed Data Back to AWS Bucket: Write the processed data back to the AWS bucket using the to_csv method.\n",
    "\n",
    "The notebook also provides additional details on connecting to the Dask Dashboard, setting AWS credentials, generating and processing random data, and writing and reading data to and from AWS. The provided code snippets and explanations guide users through each step of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54acc5-8487-4d9f-b27c-cde85cefec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7296057-c6f6-4226-8b1c-82566b704eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f53bff-e9b4-47e9-93dc-9829de59d8c6",
   "metadata": {},
   "source": [
    "### 1. Define SLURM cluster configuration\n",
    "In this section, we utilize the [SLURMCluster](https://jobqueue.dask.org/en/latest/generated/dask_jobqueue.SLURMCluster.html) object to deploy Dask within a SLURM cluster. The SLURMCluster is configured with specific parameters, including the compute queue, the number of CPU cores per job, and the memory allocated per job. To facilitate this configuration, the `job_directives_skip` argument is employed, allowing Dask to bypass specific SLURM directives related to memory. It is worth noting that the `--mem` directive needs to be skipped because it is not explicitly defined for the nodes in the SLURM configuration file (`/mnt/shared/etc/slurm/slurm.conf`) of the clusters in the Parallel Works platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351d1ec-9ddb-40fc-bbff-9738ea56b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(\n",
    "    queue = 'compute',\n",
    "    cores = 2,  # Number of CPU cores per job\n",
    "    memory = '8GB',  # Memory per job\n",
    "    job_directives_skip = ['--mem'], # Adding this argument allows Dask to ignore the memory parameter\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6533d76e-ebb3-4186-86e4-2b507a6da986",
   "metadata": {},
   "source": [
    "Next, the cluster is scaled to a desired number of workers using the adapt method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3982ef9-c06c-4ccb-8dbb-808ca6c25e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(\n",
    "    minimum = 0, \n",
    "    maximum = 2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fe74c-24da-42a9-ad3a-5487695c3f6e",
   "metadata": {},
   "source": [
    "Lastly, a Dask client is connected to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca036c-6780-4c3d-bdfb-af9ace226fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebfb13e-0d27-4ba8-a412-6be3aba6bf1d",
   "metadata": {},
   "source": [
    "### 2. Display the Dask Dashboard in Jupyter Lab\n",
    "The [Dask extension for JupyterLab](https://github.com/dask/dask-labextension) comes pre-installed in the Jupyter Lab interactive session. This extension facilitates the integration of the Dask Dashboard directly into JupyterLab, as demonstrated in this accompanying [video](https://www.youtube.com/watch?v=EX_voquHdk0). To establish the connection to the Dashboard, we employ a proxy, and you can find detailed instructions on this setup in the provided [link](https://jobqueue.dask.org/en/stable/interactive.html). \n",
    "\n",
    "In this case, simply paste the link that is generated below in the DASK DASHBOARD URL search bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8088b27-5b9d-42c8-b7a8-c47f74f76f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlsplit\n",
    "port = urlsplit(client.dashboard_link).port\n",
    "os.environ['DASHBOARD_PORT'] = str(port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b0d55a-dec2-491a-8ea5-a7006c46310a",
   "metadata": {},
   "source": [
    "**To connect to the Dashboard copy the link below in the DASK DASHBOARD URL search bar and press enter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c322f-6197-4943-8bb2-7a9326223bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo https://cloud.parallel.works/me/$openPort/proxy/$DASHBOARD_PORT/status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7fd416-5a28-469f-8b06-a3d81fbbf140",
   "metadata": {},
   "source": [
    "### 3. Set AWS credentials\n",
    "Follow the instructions in [this link](https://docs-staging.parallel.works/docs/storage/transferring-data/obtaining-credentials) to obtain the **temporary credentials** for an AWS bucket resource defined in the Parallel Works platform. AWS credentials are set as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ceddb-fae5-49c1-a1e5-fa4cb685a87f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set AWS credentials. Can obtain the credentials in this link. \n",
    "# https://docs-staging.parallel.works/docs/storage/transferring-data/obtaining-credentials\n",
    "\n",
    "bucket_name='abc'\n",
    "os.environ['AWS_ACCESS_KEY_ID']='123'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']='xyz'\n",
    "os.environ['AWS_SESSION_TOKEN']='456'\n",
    "\n",
    "# If accessing an S3 bucket on a cluster from another \n",
    "# cloud service provider, currently you need to specify \n",
    "# the URL (note the bucket region in the URL has to match\n",
    "# your bucket!) as well as the secrets for the \n",
    "# underlying s3fs library. This is not necessary if your\n",
    "# cluster happens to be in the same CSP and region as \n",
    "# your bucket. These additional storage options\n",
    "# need to be included in any bucket write commands below.\n",
    "storage_options={\"client_kwargs\": {\"endpoint_url\": \"https://s3-us-east-2.amazonaws.com\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b3211-3eb8-4af5-a795-b38b0e121f14",
   "metadata": {},
   "source": [
    "### 4. Generate random data\n",
    "In this section, a function generate_random_data is defined to create a Dask DataFrame with randomly generated data. The number of rows in the generated data can be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b66e1-6279-4643-89e6-f85e80d7b387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to generate random data\n",
    "def generate_random_data(num_rows):\n",
    "    fake = Faker()\n",
    "    data = {\n",
    "        'Name': [fake.name() for _ in range(num_rows)],\n",
    "        'Age': [fake.random_int(min=18, max=99) for _ in range(num_rows)],\n",
    "        'City': [fake.city() for _ in range(num_rows)]\n",
    "    }\n",
    "    return dd.from_pandas(pd.DataFrame(data), npartitions=2)  # Create Dask DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05b735-a7c3-4407-8582-3f10763e1fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_rows = 100000  # Adjust the number of rows as needed\n",
    "random_data = generate_random_data(num_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807e54ea-7f62-4ad1-a56a-58ffc7b5a0ce",
   "metadata": {},
   "source": [
    "### 5. Write data to the AWS bucket\n",
    "Data generated in the previous step is written to the specified AWS bucket using the to_csv method. It's important to note that Dask employs the SLURM queue to submit jobs, acquiring workers responsible for the data transfer process. To monitor the status of this job, you can execute watch squeue in a terminal within the cluster. This command provides real-time updates on the job's progress and status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a98fbe-9009-42c0-af8b-035ea896127a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_filename = 'random_data.csv'\n",
    "random_data.to_csv(f's3://{bucket_name}/{csv_filename}', index=False, single_file=True, storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb6825-edcb-459e-befd-b42e6810b40e",
   "metadata": {},
   "source": [
    "### 6. Read data from the AWS bucket\n",
    "In this section, data is read from the AWS bucket into a Dask DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd83f4d-ead6-4414-89bf-c54df165a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_df = dd.read_csv(f's3://{bucket_name}/{csv_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab9b52-8017-4543-9bed-11843923603f",
   "metadata": {},
   "source": [
    "### 7. Process data\n",
    "The Dask DataFrame is processed by filtering rows where the 'Age' column is greater than 21 and then grouping by the 'City' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d6ce0-851a-44c1-b2a1-ed6683a07837",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dask_df = dask_df[dask_df['Age'] > 21].groupby('City').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c56c55f-22f3-47d5-b74b-6188ffb91fd9",
   "metadata": {},
   "source": [
    "### 8. Write the processed data back to the AWS bucket\n",
    "The processed data is written back to the AWS bucket using the to_csv method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f94f9-62a7-466c-b059-31a7af2d3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_csv_filename = 'processed_data.csv'\n",
    "processed_dask_df.to_csv(f's3://{bucket_name}/{processed_csv_filename}', single_file=True, storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2290b91-6013-4bb5-9a3c-792e5d942bc5",
   "metadata": {},
   "source": [
    "Additionally, a sample computation is triggered using compute() to showcase the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13f851-77cb-4be7-ae12-7c26d28422f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger computation if needed\n",
    "processed_dask_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544efdc5-848f-4fba-bab1-1c5bb262015b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
